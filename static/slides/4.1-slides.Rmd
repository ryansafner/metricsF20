---
title: "4.1 — Panel Data and Fixed Effects"
subtitle: "ECON 480 • Econometrics • Fall 2020"
author: 'Ryan Safner<br> Assistant Professor of Economics <br> <a href="mailto:safner@hood.edu"><i class="fa fa-paper-plane fa-fw"></i>safner@hood.edu</a> <br> <a href="https://github.com/ryansafner/metricsF20"><i class="fa fa-github fa-fw"></i>ryansafner/metricsF20</a><br> <a href="https://metricsF20.classes.ryansafner.com"> <i class="fa fa-globe fa-fw"></i>metricsF20.classes.ryansafner.com</a><br>'
#date:
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML" # rescales math with css changes https://github.com/yihui/xaringan/issues/143
    lib_dir: libs
    df_print: paged
    css: [custom.css, "hygge"] #, metropolis, metropolis-fonts
    nature:
      beforeInit: ["macros.js", "https://platform.twitter.com/widgets.js"] # first is for rescaling images , second is for embedding tweets, https://github.com/yihui/xaringan/issues/100
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
    includes:
      in_header: header.html # for font awesome, used in title  
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo=F,
                      message=F,
                      warning=F)
library(tidyverse)
set.seed(256)
update_geom_defaults("label", list(family = "Fira Sans Condensed"))
library(gganimate)
library(broom)
```

```{r}
phones<-read_csv("../Data/cellphones.csv")
phones<-phones %>%
  select(-state_numeric) %>%
  mutate(year_num = year) %>%
  mutate_at(c("year", "state", "cell_ban", "text_ban"), as.factor) %>%
  rename(deaths = DeathsPerBillionMiles,
         cell_plans = cell_per10thous_pop)
```

# Types of Data I

.pull-left[

.smallest[
- .red[**Cross-sectional data**]: compare different individual $i$’s at same time $\bar{t}$

```{r}
phones %>%
  filter(year=="2012") %>%
  select(state, year, deaths, cell_plans) %>%
  head()
```
]
]

--

.pull-right[

.smallest[
- .blue[**Time-series data**]: track same individual $\bar{i}$ over different times $t$

```{r}
phones %>%
  filter(state=="Maryland") %>%
  select(state, year, deaths, cell_plans) %>%
  head()
```
]
]

---

# Types of Data I

.pull-left[

.smallest[
- .red[**Cross-sectional data**]: compare different individual $i$’s at same time $\bar{t}$
]

```{r, fig.height=4, fig.retina=3}
phones %>%
  filter(year=="2012") %>%
  ggplot(data = .)+
  aes(x = cell_plans,
      y = deaths)+
  geom_point(color = "red")+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=18)
```
]

.pull-right[

.smallest[
- .blue[**Time-series data**]: track same individual $\bar{i}$ over different times $t$
]

```{r, fig.height=4, fig.retina=3}
phones %>%
  filter(state=="Maryland") %>%
  ggplot(data = .)+
  aes(x = year_num,
      y = deaths)+
  geom_point(color="blue")+
  geom_path(color="blue", size = 1)+
  labs(x = "Year",
       y = "Deaths Per Billion Miles Driven")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=18)
```
]

--

- .purple[**Panel data**]: combines these dimensions: compare all individual $i$’s over all time $t$’s

---

# Panel Data I

```{r, fig.retina=3, fig.width=14, fig.align="center"}
phones %>%
  filter(state!="District of Columbia") %>%
  #group_by(state) %>%
  ggplot(data = .)+
  aes(x = cell_plans,
      y = deaths,
      color = state)+
  geom_point()+
  scale_color_viridis_d()+
  geom_path(size = 1)+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=18)+
  theme(legend.position = "none")
```


---

# Panel Data II

.pull-left[
```{r}
phones %>%
  arrange(state) %>%
  select(state, year, deaths, cell_plans)
```

]

.pull-right[

- .purple[**Panel**] or .purple[**Longitudinal**] data contains 
  - .blue[repeated observations] $(t)$
  - on .red[multiple individuals] $(i)$
]

---

# Panel Data II

.pull-left[
.smallest[
```{r}
phones %>%
  arrange(state) %>%
  select(state, year, deaths, cell_plans)
```
]
]

.pull-right[

- .purple[**Panel**] or .purple[**Longitudinal**] data contains 
  - .blue[repeated observations] $(t)$
  - on .red[multiple individuals] $(i)$

- Thus, our regression equation looks like:

$$
\begin{align}
  \hat{Y_{\color{red}{i}\color{blue}{t}}} = \beta_0 + \beta_1 X_{\color{red}{i}\color{blue}{t}} + u_{\color{red}{i}\color{blue}{t}}
\end{align}
$$

> for .red[individual `\\(i\\)`] in .blue[time `\\(t\\)`].

]

---

# Panel Data: Our Motivating Example

.pull-left[
.smallest[
```{r}
phones %>%
  arrange(state) %>%
  select(state, year, deaths, cell_plans)
```
]
]

.pull-right[

.content-box-green[
.green[**Example**]: Do cell phones cause more traffic fatalities?
]
- No measure of cell phones *used* while driving
  - `cell_plans` as a **proxy** for cell phone usage

- State-level data over 6 years

]

---

# The Data I

```{r, echo=T}
glimpse(phones)
```


---

# The Data II

.pull-left[
.smallest[
```{r, echo=T}
phones %>%
  count(state)
```
]
]

--

.pull-right[
.smallest[
```{r, echo=T}
phones %>%
  count(year)
```
]
]

---

# The Data III

.pull-left[
.smallest[
```{r, echo=T}
phones %>%
  distinct(state)
```
]
]

--

.pull-right[
.smallest[
```{r, echo=T}
phones %>%
  distinct(year)
```
]
]

---

# The Data IV

.smallest[
```{r, echo=T}
phones %>%
  summarize(States = n_distinct(state),
            Years = n_distinct(year))
```
]

---

# The Data: With plm

.pull-left[
```{r, echo=T}
# install.packages("plm")
library(plm)

pdim(phones, index=c("state","year"))
```

]

.pull-right[

- **`plm` package** for panel data in R

- `pdim()` checks dimensions of panel dataset
  - `index=` vector of "group" & "year" variables

- Returns with a summary of:
  - `n` groups
  - `T` periods
  - `N` total observaitons
]

---

# Pooled Regression I

- What if we just ran a standard regression:

$$\hat{Y_{it}}=\beta_0+\beta_1X_{it}+u_{it}$$

--
  - $N$ number of $i$ groups (e.g. U.S. States)
  - $T$ number of $t$ periods (e.g. years)

- This is a .hi[pooled regression model]: treats all observations as independent

---

# Pooled Regression II

.smallest[
```{r, echo=T}
pooled <- lm(deaths ~ cell_plans, data = phones)
pooled %>% tidy()
```
]

---

# Pooled Regression III

.pull-left[
.code60[
```{r pooled-plot,echo=T, eval=F}
ggplot(data = phones)+
  aes(x = cell_plans,
      y = deaths)+
  geom_point()+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=14)
```

]
]

.pull-right[
```{r, ref.label="pooled-plot", fig.retina=3}

```
]

---

# Pooled Regression III

.pull-left[
.code60[
```{r pooled-plot2,echo=T, eval=F}
ggplot(data = phones)+
  aes(x = cell_plans,
      y = deaths)+
  geom_point()+
  geom_smooth(method = "lm", color = "red")+ #<<
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=14)
```
]
]

.pull-right[
```{r, ref.label="pooled-plot2", fig.retina=3}

```
]


---

# Recap: Assumptions about Errors

.pull-left[
.smallest[
- Recall the .hi[4 critical **assumptions** about `\\(u\\)`]:

1. The expected value of the residuals is 0
$$E[u]=0$$

2. The variance of the residuals over $X$ is constant:
$$var(u|X)=\sigma^2_{u}$$

3. Errors are not correlated across observations: 
$$cor(u_i,u_j)=0 \quad \forall i \neq j$$

4. There is no correlation between $X$ and the error term: 
$$cor(X, u)=0 \text{ or } E[u|X]=0$$

]
]

.pull-right[

.center[
![](https://www.dropbox.com/s/95rh9ow982y5htb/error.png?raw=1)
]
]

---

# Biases of Pooled Regression

$$\hat{Y_{it}}=\beta_0+\beta_1X_{it}+\epsilon_{it}$$

- .hi-purple[Assumption 3]: $cor(u_i,u_j)=0 \quad \forall \, i \neq j$

- Pooled regression model is **biased** because it ignores:
  - Multiple observations from same group $i$
  - Multiple observations from same time $t$

- Thus, errors are .hi[serially] or .hi[auto-correlated]; $cor(u_i, u_j) \neq 0$ within same $i$ and within same $t$

---

# Biases of Pooled Regression: Our Example

$$\widehat{\text{Deaths}_{it}}=\beta_0+\beta_1 \, \text{Cell Phones}_{it}+u_{it}$$

- Multiple observations from same state $i$
  - Probably similarities among $u$ for obs in same state
  - Residuals on observations from same state are likely correlated 
  
- Multiple observations from same year $t$
  - Probably similarities among $u$ for obs in same year
  - Residuals on observations from same year are likely correlated
  
---

# Example: Consider Just 5 States

.pull-left[
.code60[
```{r 5state-plot1, echo=T, eval=F}
phones %>%
  filter(state %in% c("District of Columbia",
                      "Maryland", "Texas",
                      "California", "Kansas")) %>%
ggplot(data = .)+
  aes(x = cell_plans,
      y = deaths,
      color = state)+ #<<
  geom_point()+ #<<
  geom_smooth(method = "lm")+ #<<
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       color = NULL)+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=14)+
  theme(legend.position = "top")
```
]
]

.pull-right[
```{r, ref.label="5state-plot1", fig.retina=3}

```
]

---

# Example: Consider Just 5 States

.pull-left[
.code60[
```{r 5state-plot2, echo=T, eval=F}
phones %>%
  filter(state %in% c("District of Columbia",
                      "Maryland", "Texas",
                      "California", "Kansas")) %>%
ggplot(data = .)+
  aes(x = cell_plans,
      y = deaths,
      color = state)+ 
  geom_point()+ 
  geom_smooth(method = "lm")+ 
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       color = NULL)+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=14)+
  theme(legend.position = "none")+ #<<
  facet_wrap(~state, ncol=3) #<<
```
]
]

.pull-right[
```{r, ref.label="5state-plot2", fig.retina=3}

```
]

---

# Look at All States

.pull-left[
.code60[
```{r all-state-plot, echo=T, eval=F}
ggplot(data = phones)+ #<<
  aes(x = cell_plans,
      y = deaths,
      color = state)+ 
  geom_point()+ 
  geom_smooth(method = "lm")+ 
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       color = NULL)+
  theme_bw(base_family = "Fira Sans Condensed")+
  theme(legend.position = "none")+
  facet_wrap(~state, ncol=7) #<<
```
]
]

.pull-right[
```{r, ref.label="all-state-plot", fig.retina=3}

```
]

---

# The Bias in our Pooled Regression

.smallest[
$$\widehat{\text{Deaths}_{it}}=\beta_0+\beta_1 \, \text{Cell Phones}_{it}+\text{u}_{it}$$

- $\text{Cell Phones}_{it}$ is .hi-purple[endogenous]:
]

--

.smallest[

$$cor(\text{u}_{it}, \text{cell phones}_{it}) \neq 0 \quad \quad E[\text{u}_{it}|\text{cell phones}_{it}] \neq 0$$
]

--

.smallest[
- Things in $u_{it}$ correlated with $\text{Cell phones}_{it}$:
  - infrastructure spending, population, urban vs. rural, more/less cautious citizens, cultural attitudes towards driving, texting, etc
]

--

.smallest[
- A lot of these things vary systematically **by State**!
  - $cor(\text{u}_{it_1}, \text{u}_{it_2})\neq 0$
      - Error in State $i$ during $t_1$ correlates with error in State $i$ during $t_2$
      - things in State that don’t change over time
]

---

class: inverse, center, middle

# Fixed Effects Model

---

# Fixed Effects: DAG

.pull-left[
.smallest[
- A simple pooled model likely contains lots of omitted variable bias

- Many (often unobservable) factors that determine both Phones & Deaths
  - Culture, infrastructure, population, geography, institutions, etc
]
]

.pull-right[
```{r}
library(ggdag)
dagify(Deaths~Phones+Cultr+Insts+Geog+Pop+Infr,
       Phones~Cultr+Insts+Geog+Pop+Infr,
       coords = list(x = c(Phones = 1, Cultr = 2, Insts = 2, Infr = 3, Geog = 4, Pop = 4, Deaths = 5),
                     y = c(Phones = 0, Cultr = 1, Insts = -1, Infr = 1, Geog = 1, Pop = -1, Deaths = 0)),
       exposure = "Phones",
       outcome = "Deaths") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position = "none")
```
]

---

# Fixed Effects: DAG

.pull-left[
.smallest[
- A simple pooled model likely contains lots of omitted variable bias

- Many (often unobservable) factors that determine both Phones & Deaths
  - Culture, infrastructure, population, geography, institutions, etc

- But the beauty of this is that .hi-turquoise[most of these factors systematically vary by U.S. State and are stable over time!]

- We can simply .hi-purple[“control for State”] to safely remove the influence of all of these factors!
]
]

.pull-right[
```{r}
dagify(Deaths~Phones+State,
       Phones~State,
       coords = list(x = c(Phones = 1, State = 3, Deaths = 5),
                     y = c(Phones = 0, State = 1, Deaths = 0)),
       exposure = "Phones",
       outcome = "Deaths") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position = "none")
```

]

---

# Fixed Effects: Decomposing $\text{u}_{it}$

- Much of the endogeneity in $X_{it}$ can be explained by systematic differences across $i$ (groups)

--

- Exploit the systematic variation across groups with a .hi[fixed effects model]

--

- *Decompose* the model error term into two parts:

$$\text{u}_{it} = \alpha_i + \epsilon_{it}$$

---

# Fixed Effects: $\alpha_i$

- *Decompose* the model error term into two parts:

$$\text{u}_{it} = \color{#6A5ACD}{\alpha_i} + \epsilon_{it}$$

- $\color{#6A5ACD}{\alpha_i}$ are .hi-purple[group-specific fixed effects]
  - group $i$ tends to have higher or lower $\hat{Y}$ than other groups given regressor(s) $X_{it}$
  - estimate a separate $\alpha_i$ for each group $i$
  - essentially, estimate a separate constant (intercept) _for each group_
  - notice this is stable over time within each group (subscript only $i$, no $t)$

- .hi-purple[This includes **all** factors that do not change _within_ group *i* over time]

---

# Fixed Effects: $\epsilon_{it}$

$$\text{u}_{it} = \color{#6A5ACD}{\alpha_i} + \color{#D7250E}{\epsilon_{it}}$$

- $\color{#D7250E}{\epsilon_{it}}$ is the remaining random error
  - As usual in OLS, assume the 4 typical assumptions about this error:
    - $E[\epsilon_{it}]=0$, $var[\epsilon_{it}]=\sigma^2_{\epsilon}$, $cor(\epsilon_{it}, \epsilon_{jt})=0$, $cor(\epsilon_{it}, X_{it})=0$

- $\color{#D7250E}{\epsilon_{it}}$ includes all other factors affecting $Y_{it}$ *not* contained in group effect $\alpha_i$
  - i.e. differences *within* each group that *change* over time
  - Be careful: $X_{it}$ can still be endogenous from other factors!

---

# Fixed Effects: New Regression Equation

$$\widehat{Y}_{it} = \beta_0+\beta_1 X_{it} +\color{#6A5ACD}{\alpha_i} + \color{#D7250E}{\epsilon_{it}}$$

- We've pulled $\color{#6A5ACD}{\alpha_i}$ out of the original error term into the regression

- Essentially we’ll estimate an intercept for each .purple[group] (minus one, which is $\beta_0)$
  - avoiding the dummy variable trap

- Must have multiple observations (over time) for each group (i.e. panel data)

---

# Fixed Effects: Our Example

$$\widehat{\text{Deaths}}_{it} = \beta_0+\beta_1 \text{Cell phones}_{it} +\color{#6A5ACD}{\alpha_i}+ \color{#D7250E}{\epsilon_{it}}$$

- $\color{#6A5ACD}{\alpha_i}$ is the .hi-purple[State fixed effect]
  - Captures everything unique about each state $i$ that *does not change over time*
    - culture, institutions, history, geography, climate, etc!

- There could *still* be factors in $\color{#D7250E}{\epsilon_{it}}$ that are correlated with $\text{Cell phones}_{it}$!
  - things that do change over time within States
  - perhaps individual States have cell phone bans for *some* years in our data

---

# Estimating Fixed Effects Models

$$\widehat{Y}_{it} = \beta_0+\beta_1 X_{it} +\alpha_i+\epsilon_{it}$$

- Two methods to estimate fixed effects models:

1. Least Squares Dummy Variable (LSDV) approach

2. De-meaned data approach

---

class: inverse, center, middle

# Least Squares Dummy Variable Approach

---

# Least Squares Dummy Variable Approach

.smallest[
$$\widehat{Y_{it}}=\beta_0+\beta_1X_{it}+\beta_2 D_{1i}+ \beta_3 D_{2i} + \cdots +\beta_N D_{(N-1)i}+\epsilon_{it}$$

- A dummy variable $D_{i} = \{0,1\}$ for each possible group
  - $=1$ if observation $it$ is from group $i$, otherwise $=0$
]

--

.smallest[
- If there are $N$ groups:
  - Include $N-1$ dummies (to avoid **dummy variable trap**) and $\beta_0$ is the reference category<sup>.magenta[†]</sup>
  - So we are estimating a different intercept for each group
]

--

.smallest[
- Sounds like a lot of work, automatic in `R`
]
--

.footnote[<sup>.magenta[†]</sup> If we do not estimate `\\(\beta_0\\)`, we could include all N dummies. In either case, `\\(\beta_0\\)` takes the place of one category-dummy.]

---

# Least Squares Dummy Variable Approach: Our Example

.content-box-green[
.green[**Example**]: 
$$\widehat{\text{Deaths}_{it}}=\beta_0+\beta_1\text{Cell Phones}_{it}+\text{Alaska}_i+ \cdots +\text{Wyoming}_i$$
]

- Let Alabama be the reference category $(\beta_0)$, include all other States

---

# Our Example in R I

$$\widehat{\text{Deaths}_{it}}=\beta_0+\beta_1\text{Cell Phones}_{it}+\text{Alaska}_i+ \cdots +\text{Wyoming}_i$$

- If `state` is a `factor` variable, just include it in the regression

- `R` automatically creates $N-1$ dummy variables and includes them in the regression
  - Keeps intercept and leaves out first group dummy

---

# Our Example in R II

.tiny[
```{r fe-reg, echo=T, eval=T}
fe_reg_1 <- lm(deaths ~ cell_plans + state, data = phones)
fe_reg_1 %>% tidy()
```

]

---

class: inverse, center, middle

# De-meaned Approach

---

# De-meaned Approach I

- Alternatively, we can control our regression for group fixed effects without directly estimating them

- We simply .hi-purple[de-mean the data for each group]

--

- For each group $i$, find the means (over time, $t)$:
$$\bar{Y}_i=\beta_0+\beta_1 \bar{X}_i+\bar{\alpha}_i+\bar{\epsilon}_{it}$$
--

- Where:
  - $\bar{Y}_i$: average value of $Y_{it}$ for group $i$
  - $\bar{X}_i$: average value of $X_{it}$ for group $i$
  - $\bar{\alpha}_i$: average value of $\alpha_{i}$ for group $i$ $(=\alpha_i)$
  - $\bar{\epsilon}_{it}=0$, by assumption 1

---

# De-meaned Approach II

.smallest[
$$\begin{align*}
\widehat{Y_{it}}&=\beta_0+\beta_1X_{it}+u_{it}\\
\bar{Y}_i&=\beta_0+\beta_1 \bar{X}_i+\bar{\alpha}_i+\bar{\epsilon}_i\\
\end{align*}$$
]

--

.smallest[
- Subtract the means equation from the pooled equation to get:

$$\begin{align*}
Y_i-\bar{Y}_i&=\beta_1(X_{it}-\bar{X}_i)+\tilde{\epsilon}_{it}\\
\tilde{Y}_{it}&=\beta_1 \tilde{X}_{it}+\tilde{\epsilon}_{it}\\
\end{align*}$$
]

--

.smallest[
- Within each group $i$, the de-meaned variables $\tilde{Y}_{it}$ and $\tilde{X}_{it}$'s all have a mean of 0<sup>.magenta[†]</sup>

- Variables that don't change over time will drop out of analysis altogether

- Removes any source of variation **across** groups to only work with variation **within** each group
]

.footnote[<sup>.magenta[†]</sup> Recall **Rule 4** from the [2.3 class notes](class/2.1-class/#the-summation-operator) on the Summation Operator: `\\(\sum(X_i-\bar{X})=0\\)`]

---

# De-meaned Approach III

$$\tilde{Y}_{it}=\beta_1 \tilde{X}_{it}+\tilde{\epsilon}_{it}$$

- Yields identical results to dummy variable approach

- More useful when we have many groups (would be many dummies)

- Demonstrates **intuition** behind fixed effects:
  - Converts all data to deviations from the mean of each group
    - All groups are “centered” at 0
  - Fixed effects are often called the .hi-purple[“within” estimators], they exploit variation *within* groups, not *across* groups

---

# De-meaned Approach IV

- We are basically comparing groups *to themselves* over time
  - apples to apples comparison
  - e.g. Maryland in 2000 vs. Maryland in 2005

- Ignore all differences *between* groups, only look at differences *within* groups over time

---

# De-Meaning the Data in R I

.pull-left[
```{r demeaning, echo=T, eval=F}
# get means of Y and X by state
means_state<-phones %>%
  group_by(state) %>%
  summarize(avg_deaths = mean(deaths),
            avg_phones = mean(cell_plans))

# look at it
means_state
```
]

--

.pull-right[
.tiny[
```{r, ref.label="demeaning"}

```
]
]
---

# De-Meaning the Data in R II

.pull-left[
.code60[
```{r demeaning-plot, echo=T, eval=F}
ggplot(data = means_state)+
  aes(x = fct_reorder(state, avg_deaths),
      y = avg_deaths,
      color = state)+
  geom_point()+
  geom_segment(aes(y = 0,
                   yend = avg_deaths,
                   x = state,
                   xend = state))+
  coord_flip()+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       color = NULL)+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=10)+
  theme(legend.position = "none")
```
]
]

.pull-right[
```{r, ref.label="demeaning-plot", fig.retina=3}

```

]

---

# Visualizing "Within Estimates" for the 5 States

```{r, cache = F, fig.align="center", fig.width=14}
phones2<-phones %>%
filter(state %in% c("District of Columbia",
                      "Maryland", "Texas",
                      "California", "Kansas")) %>%
  group_by(state) %>%
  mutate(mean_phones = mean(cell_plans),
         mean_deaths = mean(deaths))

before_cor <- paste("1. Raw data: cor(cell plans, deaths) = ",round(cor(phones2$cell_plans,phones2$deaths),3),sep='')
after_cor <- paste("6. What's left: cor(cell plans, deaths) = ",round(cor(phones2$cell_plans-phones2$mean_phones,phones2$deaths-phones2$mean_deaths),3),sep='')

#Add step 2 in which X is demeaned, and 3 in which both X and Y are, and 4 which just changes label
dffull <- rbind(
  #Step 1: Raw data only
  phones2 %>% mutate(mean_phones=NA,mean_deaths=NA,time=before_cor),
  #Step 2: Add x-lines
  phones2 %>% mutate(mean_deaths=NA,time='2. Figure out any between-State differences in cell plans'),
  #Step 3: X de-meaned 
  phones2 %>% mutate(cell_plans = cell_plans - mean_phones,mean_phones=0,mean_deaths=NA,time="3. Remove all between-State differences in cell plans"),
  #Step 4: Remove X lines, add Y
  phones2 %>% mutate(cell_plans = cell_plans - mean_phones,mean_phones=NA,time="4. Figure out any between-State differences in deaths"),
  #Step 5: Y de-meaned
  phones2 %>% mutate(cell_plans = cell_plans - mean_phones,deaths = deaths - mean_deaths,mean_phones=NA,mean_deaths=0,time="5. Remove all between-State differences in deaths"),
  #Step 6: Raw demeaned data only
  phones2 %>% mutate(cell_plans = cell_plans - mean_phones,deaths = deaths - mean_deaths,mean_phones=NA,mean_deaths=NA,time=after_cor))
```

```{r, cache = F, fig.align="center", fig.width=14}
p <- ggplot(dffull,aes(y=deaths,x=cell_plans,color=as.factor(state)))+geom_point()+
  geom_vline(aes(xintercept=mean_phones,color=as.factor(state)))+
  geom_hline(aes(yintercept=mean_deaths,color=as.factor(state)))+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       title = 'The Relationship between Cell Plans and Deaths, with State Fixed Effects \n{next_state}',
       caption = "Animation inspired by Nick Huntington-Klein’s Causal Animations")+
  theme_bw(base_family = "Fira Sans Condensed", base_size = 14)+
  theme(legend.position = "none")+
  transition_states(time,transition_length=c(12,32,12,32,12,12),state_length=c(160,100,75,100,75,160),wrap=FALSE)+
  ease_aes('sine-in-out')+
  exit_fade()+enter_fade()

animate(p,nframes=200)
```

---

# Visualizing "Within Estimates" for All 51 States

```{r, cache = F, fig.align="center", fig.width=14}
phones3<-phones %>%
  group_by(state) %>%
  mutate(mean_phones = mean(cell_plans),
         mean_deaths = mean(deaths))

before_cor <- paste("1. Raw data: cor(cell plans, deaths) = ",round(cor(phones3$cell_plans,phones3$deaths),3),sep='')
after_cor <- paste("6. What's left: cor(cell plans, deaths) = ",round(cor(phones3$cell_plans-phones3$mean_phones,phones3$deaths-phones3$mean_deaths),3),sep='')

#Add step 2 in which X is demeaned, and 3 in which both X and Y are, and 4 which just changes label
dffull2 <- rbind(
  #Step 1: Raw data only
  phones3 %>% mutate(mean_phones=NA,mean_deaths=NA,time=before_cor),
  #Step 2: Add x-lines
  phones3 %>% mutate(mean_deaths=NA,time='2. Figure out any between-State differences in cell plans'),
  #Step 3: X de-meaned 
  phones3 %>% mutate(cell_plans = cell_plans - mean_phones,mean_phones=0,mean_deaths=NA,time="3. Remove all between-State differences in cell plans"),
  #Step 4: Remove X lines, add Y
  phones3 %>% mutate(cell_plans = cell_plans - mean_phones,mean_phones=NA,time="4. Figure out any between-State differences in deaths"),
  #Step 5: Y de-meaned
  phones3 %>% mutate(cell_plans = cell_plans - mean_phones,deaths = deaths - mean_deaths,mean_phones=NA,mean_deaths=0,time="5. Remove all between-State differences in deaths"),
  #Step 6: Raw demeaned data only
  phones3 %>% mutate(cell_plans = cell_plans - mean_phones,deaths = deaths - mean_deaths,mean_phones=NA,mean_deaths=NA,time=after_cor))
```

```{r, cache = F, fig.align="center", fig.width=14}
p2 <- ggplot(dffull2,aes(y=deaths,x=cell_plans,color=as.factor(state)))+geom_point()+
  geom_vline(aes(xintercept=mean_phones,color=as.factor(state)))+
  geom_hline(aes(yintercept=mean_deaths,color=as.factor(state)))+
  labs(x = "Cell Phones Per 10,000 People",
       y = "Deaths Per Billion Miles Driven",
       title = 'The Relationship between Cell Plans and Deaths, with State Fixed Effects \n{next_state}',
       caption = "Animation inspired by Nick Huntington-Klein’s Causal Animations")+
  theme_bw(base_family = "Fira Sans Condensed", base_size = 14)+
  theme(legend.position = "none")+
  transition_states(time,transition_length=c(12,32,12,32,12,12),state_length=c(160,100,75,100,75,160),wrap=FALSE)+
  ease_aes('sine-in-out')+
  exit_fade()+enter_fade()

animate(p2,nframes=200)
```

---

# De-meaned Approach in R I

- The `plm` package is designed for panel data

- `plm()` function is just like `lm()`, with some additional arguments:
  - `index="group_variable_name"` set equal to the name of your `factor` variable for the groups
  - `model=` set equal to `"within"` to use fixed-effects (within-estimator)
  
```{r plm-fe, echo=T}
#install.packages("plm")
library(plm)
fe_reg_1_alt<-plm(deaths ~ cell_plans,
                  data = phones,
                  index = "state",
                  model = "within")
```

---

# De-meaned Approach in R II

.quitesmall[
```{r, echo=T}
fe_reg_1_alt %>% tidy()
```
]

---

class: inverse, center, middle

# Two-Way Fixed Effects

---

# Two-Way Fixed Effects

.pull-left[
.smallest[
- State fixed effect controls for all factors that vary by state but are stable over time

- But there are still other (often unobservable) factors that affect both Phones and Deaths, that *don’t* vary by State
  - The country’s macroeconomic performance, federal laws, etc
]
]

.pull-right[
```{r}
library(ggdag)
dagify(Deaths~Phones+State+Macro+FedLaw,
       Phones~State+Macro+FedLaw,
       coords = list(x = c(Phones = 1, Macro = 2, State = 3, FedLaw = 4, Deaths = 5),
                     y = c(Phones = 0, Macro = 1, State = -1, FedLaw = 1, Geog = 1, Pop = -1, Deaths = 0)),
       exposure = "Phones",
       outcome = "Deaths") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position = "none")
```
]

---

# Two-Way Fixed Effects

.pull-left[

.smallest[
- State fixed effect controls for all factors that vary by state but are stable over time

- But there are still other (often unobservable) factors that affect both Phones and Deaths, that *don’t* vary by State
  - The country’s macroeconomic performance, federal laws, etc

- If these factors systematically vary over time, but are the same by State, then we can .hi-purple[“control for Year”] to safely remove the influence of all of these factors!
]
]
.pull-right[
```{r}
dagify(Deaths~Phones+State+Year,
       Phones~State+Year,
       coords = list(x = c(Phones = 1, State = 3, Year = 3, Deaths = 5),
                     y = c(Phones = 0, State = -1, Year = 1, Deaths = 0)),
       exposure = "Phones",
       outcome = "Deaths") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position = "none")
```

]

---

# Two-Way Fixed Effects

- A .hi[one-way fixed effects model] estimates a fixed effect for **groups**

--

- .hi[Two-way fixed effects model] estimates fixed effects for *both* **groups** *and* **time periods**
$$\hat{Y_{it}}=\beta_0+\beta_1 X_{it}+ \color{#6A5ACD}{\alpha_{i}} + \color{#44C1C4}{\theta_{t}} + \color{#e64173}{\nu_{it}}$$

- $\color{#6A5ACD}{\alpha_{i}}$: group fixed effects
  - accounts for **time-invariant differences across groups**

- $\color{#44C1C4}{\theta_{t}}$: time fixed effects
  - accounts for **group-invariant differences over time**

- $\color{#e64173}{\nu_{it}}$ remaining random error
  - all remaining factors that affect $Y_{it}$ that vary by state *and* change over time
  
---

# Two-Way Fixed Effects: Our Example

$$\widehat{\text{Deaths}}_{it} = \beta_0+\beta_1 \text{Cell phones}_{it} +\color{#6A5ACD}{\alpha_{i}} + \color{#44C1C4}{\theta_{t}} +  \color{#e64173}{\nu_{it}}$$

- $\color{#6A5ACD}{\alpha_{i}}$: .purple[State fixed effects]
    - differences **across states** that are **stable over time** (note subscript $i$ only)
    - e.g. geography, culture, (unchanging) state laws

- $\color{#44C1C4}{\theta_{t}}$: .turquoise[Year fixed effects]
    - differences **over time** that are **stable across states** (note subscript $t$ only)
    - e.g. economy-wide macroeconomic changes, *federal* laws passed

---

# Visualizing Year Effects I

.smallest[
```{r, echo=T}
# find averages for years
means_year<-phones %>%
  group_by(year) %>%
  summarize(avg_deaths = mean(deaths),
            avg_phones = mean(cell_plans))
means_year
```
]

---

# Visualizing Year Effects II

.pull-left[
.code60[
```{r years-plot,echo=T, eval=F}
ggplot(data = phones)+
  aes(x = year,
      y = deaths)+
  geom_point(aes(color = year))+
  
  # Add the yearly means as black points
  geom_point(data = means_year,
             aes(x = year,
                 y = avg_deaths),
             size = 3,
             color = "black")+
  
  geom_path(data = means_year,
            aes(x = year,
                y = avg_deaths),
            size = 1)+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size = 14)+
  theme(legend.position = "none")
```
]
]

.pull-right[
```{r, ref.label="years-plot", fig.retina=3}

```
]

---

# Estimating Two-Way Fixed Effects

$$\widehat{Y}_{it} = \beta_0+\beta_1 X_{it} +\alpha_i+\theta_t+\nu_{it}$$

- As before, several equivalent ways to estimate two-way fixed effects models:

1) **Least Squares Dummy Variable (LSDV) Approach**: add dummies for both groups and time periods (separate intercepts for groups and times)

--

2) **Fully De-meaned data**: 
$$\tilde{Y}_{it}=\beta_1\tilde{X}_{it}+\tilde{\nu}_{it}$$

where for each variable: $\tilde{var}_{it}=var_{it}-\overline{var}_{t}-\overline{var}_{i}$

--

3) **Hybrid**: de-mean for one effect (groups or years) and add dummies for the other effect (years or groups)

---

# LSDV Method

.quitesmall[
.code60[
```{r fe2-reg, echo=T, eval=T}
fe2_reg_1 <- lm(deaths ~ cell_plans + state + year,
                data = phones)
fe2_reg_1 %>% tidy()
```
]
]

---

# With plm

.quitesmall[
.code60[
```{r fe2-reg2, echo=T, eval=T}
fe2_reg_2 <- plm(deaths ~ cell_plans,
                 index = c("state", "year"),
                 model = "within",
                 data = phones)
fe2_reg_2 %>% tidy()
```
]
]
.smallest[
- `plm()` command allows for multiple effects to be fit inside `index=c("group", "time")`
]

---

# Adding Covariates

.pull-left[
.quitesmall[
- State fixed effect absorbs all unobserved factors that vary by state, but are constant over time

- Year fixed effect absorbs all unobserved factors that vary by year, but are constant over States

- But there are still other (often unobservable) factors that affect both Phones and Deaths, that *vary* by State *and* change over time!
  - *Some* States *change* their laws during the time period
  - State *urbanization* rates *change* over the time period

- We will also need to .hi-purple[control for these variables] (*not* picked up by fixed effects!)
  - Add them to the regression
]
]
.pull-right[
```{r}
dagify(Deaths~Phones+State+Year+Bans+Urban,
       Phones~State+Year+Bans+Urban,
       coords = list(x = c(Phones = 1, Bans = 2, State = 2, Year = 4, Urban = 4, Deaths = 5),
                     y = c(Phones = 0, Bans = 1, State = -1, Year = -1, Urban = 1, Deaths = 0)),
       exposure = "Phones",
       outcome = "Deaths") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position = "none")
```
]

---

# Adding Covariates I

$$\widehat{\text{Deaths}_{it}}=\beta_1\text{Cell Phones}_{it}+\alpha_i+\theta_t+\text{urban pct}_{it}+\text{cell ban}_{it}+\text{text ban}_{it}$$

- Can still add covariates to remove endogeneity not soaked up by fixed effects
  - factors that change within groups over time 
  - e.g. some states pass bans over the time period in data (some years before, some years after)


---

# Adding Covariates II

.quitesmall[
.code60[
```{r, echo=T}
fe2_controls_reg <- plm(deaths ~ cell_plans + text_ban + urban_percent + cell_ban,
                        data = phones,
                        index = c("state","year"),
                        model = "within",
                        effect = "twoways") 

fe2_controls_reg %>% tidy()
```
]
]

---

# Comparing Models

.pull-left[
.code50[
```{r huxout, echo=T, eval =F}
library(huxtable)
huxreg("Pooled" = pooled,
       "State Effects" = fe_reg_1,
       "State & Year Effects" = fe2_reg_1,
       "With Controls" = fe2_controls_reg,
       coefs = c("Intercept" = "(Intercept)",
                 "Cell phones" = "cell_plans",
                 "Cell Ban" = "cell_ban1",
                 "Texting Ban" = "text_ban1",
                 "Urbanization Rate" = "urban_percent"),
       statistics = c("N" = "nobs",
                      "R-Squared" = "r.squared",
                      "SER" = "sigma"),
       number_format = 4)
```
]
]

.pull-right[

.tiny[
```{r, ref.label="huxout"}
huxout
```
]

]