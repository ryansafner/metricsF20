---
title: "3.4 — Multivariate OLS Estimators: Bias, Precision, and Fit — R Practice"
author: "Solutions"
date: "ECON 480 — Econometrics — Fall 2020"
output:
  html_document:
    df_print: paged
    #theme: 
    toc: true 
    toc_depth: 3
    toc_float: true
    code_folding: show
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
Download and read in (`read_csv`) the data below. 

- [<i class="fas fa-table"></i> `speeding_tickets.csv`](https://metricsf20.classes.ryansafner.com/data/speeding-tickets.csv)

This data comes from a paper by Makowsky and Strattman (2009) that we will examine later. Even though state law sets a formula for tickets based on how fast a person was driving, police officers in practice often deviate from that formula. This dataset includes information on all traffic stops. An amount for the fine is given only for observations in which the police officer decided to assess a fine. There are a number of variables in this dataset, but the one's we'll look at are:

| Variable | Description |
|----------|-------------|
| `Amount` | Amount of fine (in dollars) assessed for speeding |
| `Age` | Age of speeding driver (in years) |
| `MPHover` | Miles per hour over the speed limit |

We want to explore who gets fines, and how much. We'll come back to the other variables (which are categorical) in this dataset in later lessons.

---

<!--ANSWER BELOW HERE-->

```{r}
library(tidyverse)
speed<-read_csv("https://metricsf20.classes.ryansafner.com/data/speeding_tickets.csv")
```

---

## Question 2
*How does the age of a driver affect the amount of the fine*? Make a scatterplot of the `Amount` of the fine and the driver's `Age`. Add a regression line with an additional layer of `geom_smooth(method="lm")`.

---

<!--ANSWER BELOW HERE-->

```{r}
ggplot(data = speed)+
  aes(x = Age,
      y = Amount)+
  geom_point()+
  geom_smooth(method = "lm")
```

---

## Question 3
Find the correlation between `Amount` and `Age`.^[Note there are a lot of `NA`s (missing data) for `Amount`. You can verify by `summary()` or `count()` if you wish. In order to get a correlation, you will need to put `use="pairwise.complete.obs"` inside the `cor()` command.]

---

<!--ANSWER BELOW HERE-->

```{r}
# get summary of Amount
speed %>%
  select(Amount) %>%
  summary() # see there are 36,683 NA's!

# so we need to get correlation by dropping the NA's

# method 1: filter by non-NA observations for Amount
speed %>%
  select(Age, Amount) %>%
  filter(!is.na(Amount)) %>%
  cor()

# method 2: tell cor() to use "pairwise.complete.obs"
speed %>%
  select(Age, Amount) %>%
  cor(., use = "pairwise.complete.obs")

# note again I am using the tidyverse method of getting correlation

# you can also use summarize():
speed %>% summarize(my_cor = cor(Age, Amount, use = "pairwise.complete.obs"))

# or the Base R method:
cor(speed$Age, speed$Amount, use = "pairwise.complete.obs")
```

---

## Question 4
We want to predict the following model:

$$\widehat{\text{Amount}_i}= \hat{\beta_0}+\hat{\beta_1}\text{Age}_i$$

Run a regression, and save it as an object. Now get a `summary()` of it.

---

<!--ANSWER BELOW HERE-->

```{r}
reg1<-lm(Amount~Age, data = speed)
summary(reg1)
```

---

### Part A

Write out the estimated regression equation.

---

<!--ANSWER BELOW HERE-->

$$\widehat{\text{Amount}_i}=131.71-0.29 \, \text{Age}_i$$
```{r}
# if you want to use equatiomatic
library(equatiomatic)
extract_eq(reg1, use_coefs = TRUE, fix_signs = TRUE, coef_digits = 2)
```

---

### Part B

What is $\hat{\beta_0}$? What does it mean in the context of our question?

---

$\hat{\beta_0}=131.71$. It means when `Age` is 0, the fine `Amount` is expected to be $131.71.

---


### Part C

What is $\hat{\beta_1}$? What does it mean in the context of our question?

---

$\hat{\beta_1}=-0.29$. It means for every additional year old someone is, their expected `Amount` of the fine decreases by $0.29.

---

### Part D

What is the marginal effect of age on amount?

---

The marginal effect is $\hat{\beta_1}$, described in the previous part. Just checking to make sure you know it's the marginal effect!

---

## Question 5
Redo question 4 with the `broom` package. Try out `tidy()` and `glance()`. This is just to keep you versatile.

---

<!--ANSWER BELOW HERE-->

```{r}
library(broom)
# tidy() to get coefficients
reg1_tidy<-tidy(reg1)

reg1_tidy

# glance() at original reg for measures of fit
glance(reg1)
```

---

## Question 6

How big would the difference in expected fine be for two drivers, one 18 years old and one 40 years old?

---

<!--ANSWER BELOW HERE-->

18-year-old driver:

$$\begin{align*}
\widehat{Amount}_i &= \hat{\beta_0}+\hat{\beta_1}Age_i\\
&= 131.71-0.29(18)\\
&=126.49\\
\end{align*}$$

40-year-old driver:

$$\begin{align*}
\widehat{Amount}_i &= \hat{\beta_0}+\hat{\beta_1}Age_i\\
&= 131.71-0.29(40)\\
&=120.11\\
\end{align*}$$

The difference is $126.49-120.11=6.38$ only!

```{r}
# we can use R as a calculator and use the regression coefficients

# extract beta0 and save it
beta_0<-reg1_tidy %>%
  filter(term=="(Intercept)") %>%
  select(estimate)

# extract beta1 and save it
beta_1<-reg1_tidy %>%
  filter(term=="Age") %>%
  select(estimate)

# predicted amount for 18 year old
amount_18yr<-beta_0+beta_1*18

# predicted amount for 40 year old
amount_40yr<-beta_0+beta_1*40

# difference
amount_18yr-amount_40yr
```

---

## Question 7

Now run the regression again, controlling for speed (`MPHover`).

<!--ANSWER BELOW HERE-->

```{r}
reg2<-lm(Amount~Age+MPHover, data=speed)
summary(reg2)
```

---

### Part A
Write the new regression equation.

---

<!--ANSWER BELOW HERE-->

$$\widehat{\text{Amount}_i}=3.49+0.02 \, \text{Age}_i+6.89 \, \text{MPHover}_i$$

```{r}
# if you want to use equatiomatic
extract_eq(reg2, use_coefs = TRUE, fix_signs = TRUE, coef_digits = 2)
```

---

### Part B
What is the marginal effect of `Age` on `Amount`? What happened to it?

---

<!--ANSWER BELOW HERE-->

$\hat{\beta_1}=0.02$. For every additional year old someone is, *holding their speed constant*, their expected fine increases by $0.02. The magnitude of the effect shrank and it switched from negative to positive!

---

### Part C
What is the marginal effect of `MPHover` on `Amount`?

---

<!--ANSWER BELOW HERE-->

$\hat{\beta_2}=6.89$. For every additional MPH someone drives above the speed limit, *holding their Age constant*, their expected fine increases by $6.89 

---

### Part D
What is $\hat{\beta_0}$, and what does it mean?

---

<!--ANSWER BELOW HERE-->

$\hat{\beta_0}=3.49$. This is the expected fine for a driver of `Age` $=0$ and `MPHover` $=0$.

---

### Part E
What is the adjusted $\bar{R}^2$? What does it mean?

---

It is $0.5026$. We can explain 50% of the variation in `Amount` from variation in our model.

---

## Question 8

Now suppose both the 18 year old and the 40 year old each went 10 MPH over the speed limit. How big would the difference in expected fine be for the two drivers?

---

<!--ANSWER BELOW HERE-->

18-year-old driver:

$$\begin{align*}
\widehat{Amount}_i &= \hat{\beta_0}+\hat{\beta_1}Age_i+\hat{\beta_2}MPHover_i\\
&= 3.49+0.02(18)+6.89(10)\\
&=72.75\\
\end{align*}$$

40-year-old driver:

$$\begin{align*}
\widehat{Amount}_i &= \hat{\beta_0}+\hat{\beta_1}Age_i+\hat{\beta_2}MPHover_i\\
&= 3.49+0.02(40)+6.89(10)\\
&=73.19\\
\end{align*}$$

The difference is $72.75-73.19=-0.44$ only!

```{r}
# we can use R as a calculator and use the regression coefficients

# first we need to tidy reg2
reg2_tidy<-tidy(reg2)

# extract beta0 and save it
multi_beta_0<-reg2_tidy %>%
  filter(term=="(Intercept)") %>%
  select(estimate)

# extract beta1 and save it
multi_beta_1<-reg2_tidy %>%
  filter(term=="Age") %>%
  select(estimate)

# extract beta2 and save it
multi_beta_2<-reg2_tidy %>%
  filter(term=="MPHover") %>%
  select(estimate)

# predicted amount for 18 year old going 10 MPH over
amount_18yr_10mph<-multi_beta_0+multi_beta_1*18+multi_beta_2*10

# predicted amount for 40 year old going 10 MPH over
amount_40yr_10mph<-multi_beta_0+multi_beta_1*40+multi_beta_2*10

# difference
amount_18yr_10mph-amount_40yr_10mph # close, we have some rounding error!
```

---

## Question 9

How about the difference in expected fine between two 18 year olds, one who went 10 MPH over, and one who went 30 MPH over?

---

<!--ANSWER BELOW HERE-->

18-year-old driver, 10 MPH over: we saw was $72.75.

18-year-old driver, 30 MPH over:

$$\begin{align*}
\widehat{Amount}_i &= \hat{\beta_0}+\hat{\beta_1}Age_i+\hat{\beta_2}MPHover_i\\
&= 3.49+0.02(18)+6.89(30)\\
&=210.55\\
\end{align*}$$

The difference is now $210.55-72.75=-137.80$!

```{r}
# we can use R as a calculator and use the regression coefficients

# predicted amount for 40 year old going 30 MPH over
amount_18yr_30mph<-multi_beta_0+multi_beta_1*18+multi_beta_2*30

# difference
amount_18yr_30mph-amount_18yr_10mph
```

So clearly the speed plays a *much* bigger role than age does!

---

## Question 10

Use the `huxtable` package's `huxreg()` command to make a regression table of your two regressions: the one from question 4, and the one from question 7.

---

<!--ANSWER BELOW HERE-->

```{r}
library(huxtable)
huxreg(reg1,reg2) # the default

# some customization
huxreg("Simple OLS"=reg1,
       "Mulitvariate OLS"=reg2,
       coefs = c("Constant" = "(Intercept)",
                 "Age" = "Age",
                 "MPH Over" = "MPHover"),
       statistics = c("N" = "nobs",
                      "R-Squared" = "r.squared",
                      "SER" = "sigma"),
       number_format = 2)

```

Look at that change in $R^2$!

---

## Question 11
Are our two independent variables multicollinear? Do younger people tend to drive faster?

### Part A
Get the correlation between `Age` and `MPHover`.

---

<!--ANSWER BELOW HERE-->

```{r}
# same alternative methods as question 3

# fortunately no NA's here!

speed %>%
  select(Age, MPHover) %>%
  cor()
```

---

### Part B
Make a scatterplot of `MPHover` on `Age`.

---

<!--ANSWER BELOW HERE-->

```{r}
ggplot(data = speed)+
  aes(x = Age,
      y = MPHover)+
  geom_point()+
  geom_smooth(method = "lm")
```

---

### Part C
Run an auxiliary regression of `MPHover` on `Age`.

---

<!--ANSWER BELOW HERE-->

```{r}
reg_aux<-lm(MPHover~Age, data = speed)
summary(reg_aux)
```

---

### Part D
Interpret the coefficient on `Age`.

---

<!--ANSWER BELOW HERE-->

In our notation, this is $\hat{\delta_1}=-0.03$, which says for every 1 year older someone is, they drive 0.03 MPH less over the speed limit.

---

### Part E

Look at your regression table in question 10. What happened to the standard error on `Age`? Why (consider the formula for variation in $\hat{\beta_1})$

---

<!--ANSWER BELOW HERE-->

The formula for $var[\hat{\beta_1}]=\frac{1}{1-R^2_1} \times \frac{SER^2}{n \times var[Age]}$

The standard error of the regression (SER) went from 56.13 to 39.67!^[Note: you need to be sure to show `sigma` in your `huxreg()` or look at each of your regression results with broom's `glance()` or Base R's `summary()` output.] Adding the second variable created a much better fit, which lowered variance on the betas (and hence, standard error, the square root of variance).

Variance might have slightly increased to more than it otherwise would be, due to multicollinearity between `Age` and `MPHover`, which we investigate next.

---

### Part F

Calculate the Variance Inflation Factor (VIF) using the `car` package's `vif()` command.^[Run it on your multivariate regression object from Question 7.]

---

<!--ANSWER BELOW HERE-->

```{r}
library(car)
vif(reg2)
```

The VIF is 1.01 for $\hat{\beta_1}$ and $\hat{\beta_2}$. Variance increases only by 1% due to (weak) multicollinearity between `Age` and `MPHover`.

---

### Part G
Calculate the VIF manually, using what you learned in this question.

---

<!--ANSWER BELOW HERE-->

$VIF=\frac{1}{1-R^2_1}$, where $R^2_1$ comes from the auxiliary regression of `MPHover` on `Age` (Part C). The $R^2$ from that regression was $0.011$, so:

$$\begin{align*}
VIF&=\frac{1}{1-R^2_1}\\
&=\frac{1}{1-0.011}\\
&=\frac{1}{0.989}\\
& \approx 1.011\\
\end{align*}$$

```{r}
# we can do this in R

# first we need to extract and save the R-squared from the aux reg
# use broom's glance()

aux_r_sq<-glance(reg_aux)$r.squared %>%
  round(.,3) # round to 3 decimals

vif<-1/(1-aux_r_sq)
vif
```

Again, we have some slight rounding error.

---

## Question 12
Let's now think about the omitted variable bias. Suppose the "true" model is the one we ran from Question 7.

### Part A
Do you suppose that `MPHover` fits the two criteria for omitted variable bias?

---

<!--ANSWER BELOW HERE-->

1. `MPHover` probably affects `Amount`
2. $cor(MPHover, Age) \neq 0$

Possibly, though it is only weakly correlated with Age $(-0.10)$. Speed clearly has a big role to play in affecting and predicting fines, but probably does not add very much bias to the marginal effect of Age on Amount.

---

### Part B

Look at the regression we ran in Question 4. Consider this the "omitted" regression, where we left out `MPHover`. Does our estimate of the marginal effect of `Age` on `Amount` overstate or understate the *true* marginal effect?

---

<!--ANSWER BELOW HERE-->

Since there is negative correlation between `MPHover` and `Age`, $\hat{\beta_1}$ likely understates the effect of `Age` on `Amount.`

---

### Part C

Use the "true" model (Question 7), the "omitted" regression (Question 4), and our "auxiliary" regression (Question 11) to identify each of the following parameters that describe our biased estimate of the marginal effect of `Age` on `Amount`:^[See the notation from class 3.2.]
$$\alpha_1=\beta_1+\beta_2\delta_1$$

---

<!--ANSWER BELOW HERE-->

Using our notation from class, and the regressions from questions 4, 7, and 11, we have three regressions:

- **True Model**: $\widehat{\text{Amount}_i}=3.49+0.02 \, \text{Age}_i+6.89 \, \text{MPHover}_i$
- **Omitted Reg**: $\widehat{\text{Amount}_i}=131.71-0.29 \, \text{Age}_i$
- **Auxiliary Reg**: $\widehat{\text{MPHover}_i}=16.54-0.04 \, \text{Age}_i$

$$\begin{align*}
\hat{\alpha_1}&=\beta_1+\beta_2 \delta_1\\
-0.29 &= 0.02+6.89(-0.04)\\
\end{align*}$$

Where:

- $\beta_1=0.02$: the true marginal effect of `Age` on `Amount` (holding `MPHover` constant)
- $\beta_2=6.89$: the true marginal effect of `MPHover` on `Amount` (holding `Age` constant)
- $\delta_1=6.89$: the (auxiliary) effect of `MPHover` on `Age`

We have some slight rounding error, but this is the relationship.

---

### Part D

From your answer in part C, how large is the omitted variable bias from leaving out `MPHover`?

---

<!--ANSWER BELOW HERE-->

$$\begin{align*}
\hat{\alpha_1}&=\beta_1+\underbrace{\beta_2 \delta_1}_{Bias}\\
-0.29 &= 0.02+\underbrace{6.89(-0.04)}_{bias}\\
Bias &=-0.2756\\
\end{align*}$$

---

## Question 13
Make a coefficient plot of your coefficients from the regression in Question 7. The package `modelsummary` (which you will need to install and load) has a great command `modelplot()` to do this on your regression object.

<!--ANSWER BELOW HERE-->

```{r}
# first we have to make sure to tidy our reg with confidence intervals!
reg2_tidy<-tidy(reg2, conf.int=TRUE)

ggplot(data = reg2_tidy)+
  aes(x = estimate,
      y = term,
      color = term)+
    geom_point()+ # point for estimate
    # now make "error bars" using conf. int.
    geom_segment(aes(x = conf.low,
                     xend = conf.high,
                     y=term,
                     yend=term))+
  # add line at 0
  geom_vline(xintercept=0, size=1, color="black", linetype="dashed")+
  #scale_x_continuous(breaks=seq(-1.5,0.5,0.5),
  #                   limits=c(-1.5,0.5))+
  labs(x = expression(paste("Marginal effect, ", hat(beta[j]))),
       y = "Variable")+
  guides(color=F)+ # hide legend
  theme_classic(base_family = "Fira Sans Condensed",
           base_size=20)
```

You can also do this with the `modelsummary` package instead:

```{r}
library(modelsummary)

modelplot(reg2)
```
